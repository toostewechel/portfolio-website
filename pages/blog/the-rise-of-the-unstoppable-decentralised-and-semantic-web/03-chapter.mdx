import TableOfContentSection from "../../../components/toc/TableOfContentSection.tsx";

<TableOfContentSection chapter="chapter-03" topic="The End Game">

### The End Game

Back in 1989, the inventor of the **World Wide Web** and true visionary, Tim Berners-Lee, already had the vision of a web of data, where information has a well-defined meaning, enabling computers and people to work in better cooperation. Unfortunately, for various reasons, it didn’t take off the first time, but as more layers of the web matured and became standardised over the years, it is now making its comeback.

Currently, information on the web is mainly for human consumption and is not machine-readable. The main aim of the Semantic Web is to create distributed, interoperable and well-defined data. You can make data semantic by adding metadata according to the **Resource Description Framework** (RDF) or through **Natural Language Processing (NLP)**. Simply put, metadata gives meaning to data and contains information needed to understand and find it more quickly. The goal of NLP is to make human language, which is complex and ambiguous, easy for machines to understand. Virtual Artificial Intelligence (AI) Assistants like **Siri** and **Alexa** are famous examples that use NLP.

As a result, applications can use semantic data for search and discovery, automation tasks, aggregation and data exchange between applications, ultimately creating a more intelligent web. If we can achieve this vision, the web will become more powerful and easier to use. It would be like Wikipedia or Google, but far more encompassing and transformational. You could, for example, ask what the effect of the weather in Ireland is on cow prices and compute, in real-time, the likely cost of a steak at the supermarket. Or you could ask to book an appointment at a medical centre affiliated with your healthcare insurance within a radius of 10 km of your location next week, preferably on a Tuesday or Thursday between 9:00 AM and 12:00 AM.

Through **agent-based technologies**, applications can mediate between user needs and different available information sources. Agents, also known as **digital twins**, can represent individuals, organisations or objects and look after their interests. They can act independently of constant input from their owner and autonomously execute actions to achieve their goal. Their purpose is to generate economic value for their owner in clearly defined domains.

As people nowadays experience an endless onslaught of demand on their time and mental capacity, these intelligent digital twins can help save time by off-loading repetitive tasks and making complex decisions on behalf of its user in an ever-growing sea of information resources.

</TableOfContentSection>

<TableOfContentSection chapter="chapter-03" topic="Standing at a Crossroads">

### Standing at a Crossroads

As we slowly move into the third era of the internet, most of the core services you use and love today will likely be almost entirely rearchitected in the coming decades. Decentralised systems and semantic agent technologies will enable a more resilient and intelligent web to work automatically for its user’s (economic) interest. Whether decentralised or centralised systems win in the third era will ultimately come down to multiple factors. It depends on who will build the most user-friendly and compelling products and systems, who can win over the most high-quality developers and entrepreneurs and who can best comply with stringent regulations.

Centralised systems often start fully-fledged: they are highly usable, performant, and efficient. They can quickly reach economies of scale, but they only get better at how quickly employees at the sponsoring company improve them. Decentralised systems, on the other hand, often start clunky with noticeable limitations in usability and performance but grow exponentially under the right conditions as they attract more contributors and reach product-market fit. The recent **goldrush** and future promises of cryptocurrency networks have undoubtedly increased the interest in and accelerated the rate of development of decentralised applications. The big question remains how and if decentralised systems can withstand the natural tendency to centralise, especially now when there is (big) money to be made.

Nevertheless, at its core, the debate is not really about centralisation versus decentralisation. It is about whether or not future developments in the next era of the internet are **net good** or **bad** for humanity, not just as it stands today in an early form, but also in the promise it holds. It is all about the values users care about, and if those values don’t align, those users can choose to take their data and money and move to another platform.

</TableOfContentSection>
